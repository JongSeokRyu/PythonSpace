# ID: 2021220942
# NAME: 류종석
# File name: hw02-2.py
# Platform: Python 3.9.0 on Window 10 (PyCharm)
# Required Package(s): numpy, pandas, matplotlib, sklearn

"""Iris Perceptron

Automatically generated by Colaboratory.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score


class Perceptron:
    """
    Perceptron neuron
    """

    def __init__(self, learning_rate=0.1):
        """
        instantiate a new Perceptron

        :param learning_rate: coefficient used to tune the model
        response to training data
        """
        self.learning_rate = learning_rate
        self._b = 0.0  # y-intercept
        self._w = None  # weights assigned to input features
        # count of errors during each iteration
        self.misclassified_samples = []

    def fit(self, x: np.array, y: np.array, n_iter=10):
        """
        fit the Perceptron model on the training data

        :param x: samples to fit the model on
        :param y: labels of the training samples
        :param n_iter: number of training iterations
        """
        self._b = 0.0
        self._w = np.zeros(x.shape[1])   # 가중치 0으로 초기화
        self.misclassified_samples = []

        for _ in range(n_iter):
            # counter of the errors during this training iteration
            errors = 0
            for xi, yi in zip(x, y):
                # for each sample compute the update value
                update = self.learning_rate * (yi - self.predict(xi))
                # and apply it to the y-intercept and weights array
                self._b += update
                self._w += update * xi
                errors += int(update != 0.0)

            self.misclassified_samples.append(errors)

    def f(self, x: np.array) -> float:
        """
        compute the output of the neuron
        :param x: input features
        :return: the output of the neuron
        """
        return np.dot(x, self._w) + self._b

    def predict(self, x: np.array):
        """
        convert the output of the neuron to a binary output
        :param x: input features
        :return: 1 if the output for the sample is positive (or zero),
        -1 otherwise
        """
        return np.where(self.f(x) >= 0, 1, -1)


url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
# download and convert the csv into a DataFrame
df = pd.read_csv(url, header=None)
df.head()

# extract the label column
y = df.iloc[:, 4].values

# Versicolor, Virginica 데이터만 가져와서 배열 재조합
y1 = np.array(y[50:100])
y2 = np.array(y[100:150])
y = np.concatenate((y1,y2))
y = y[0:100]
y = np.where(y == 'Iris-versicolor', 1, -1) # versicolor 맞으면1 아니면 -1
# print(y)

# extract features
x = df.iloc[:, 0:4].values

# Versicolor, Virginica 데이터만 가져와서 배열 재조합
x1 = np.array(x[50:100])    # versicolor 데이터 4종류들
x2 = np.array(x[100:150])   # virginica 데이터 4종류들
x = np.concatenate((x1,x2))
x = x[0:100]
#print(x)

from sklearn.model_selection import train_test_split

# standardization of the features
# 데이터프레임 열개수 -1 만큼 반복 (데이터 열만 정규화)
for i in range(0,df.shape[1]-1):
    x[:, i] = (x[:, i] - x[:, i].mean()) / x[:, i].std()

# split the data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)

# train the model
classifier = Perceptron(learning_rate=0.01)
classifier.fit(x_train, y_train)
print(classifier.misclassified_samples)
print("accuracy %f" % accuracy_score(classifier.predict(x_test), y_test))

# plot the number of errors during each iteration
plt.plot(range(1, len(classifier.misclassified_samples) + 1), classifier.misclassified_samples, marker='o')
plt.xlabel('Epoch')
plt.ylabel('Errors')
plt.show()

